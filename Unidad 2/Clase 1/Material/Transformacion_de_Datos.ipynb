{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f551bafd",
   "metadata": {},
   "source": [
    "## 1. Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43cd370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librer√≠as de sklearn para transformaciones\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    Normalizer,\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder\n",
    ")\n",
    "\n",
    "# Para comparar modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444057fb",
   "metadata": {},
   "source": [
    "## 2. Cargar y Preparar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset del Titanic\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "print(\"Dimensiones del dataset:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3dc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n general\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbdd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar tipos de variables\n",
    "print(\"Variables num√©ricas:\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(numeric_cols)\n",
    "\n",
    "print(\"\\nVariables categ√≥ricas:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3facea0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTE I: NORMALIZACI√ìN Y ESCALADO\n",
    "\n",
    "## ¬øPor qu√© normalizar?\n",
    "\n",
    "Muchos algoritmos de Machine Learning son sensibles a la escala de las caracter√≠sticas:\n",
    "\n",
    "- **Regresi√≥n Log√≠stica**: Converge m√°s r√°pido con datos escalados\n",
    "- **SVM**: Muy sensible a la escala\n",
    "- **K-Means**: Usa distancias euclideas\n",
    "- **Redes Neuronales**: Entrenan mejor con datos normalizados\n",
    "- **KNN**: Basado en distancias\n",
    "\n",
    "**Algoritmos que NO requieren escalado**: √Årboles de decisi√≥n, Random Forest, XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df71ac",
   "metadata": {},
   "source": [
    "## 3. An√°lisis de Escalas Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66093138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar variables num√©ricas para an√°lisis\n",
    "features_for_scaling = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "\n",
    "# Estad√≠sticas descriptivas\n",
    "print(\"Estad√≠sticas de las variables originales:\")\n",
    "print(\"=\"*70)\n",
    "df[features_for_scaling].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf36e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las diferentes escalas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(features_for_scaling):\n",
    "    axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribuci√≥n de {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Valor')\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "    axes[idx].axvline(df[col].mean(), color='red', linestyle='--', label=f'Media: {df[col].mean():.2f}')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Observa las diferentes escalas:\")\n",
    "print(f\"   - Age: rango aproximado 0-80\")\n",
    "print(f\"   - Fare: rango aproximado 0-500\")\n",
    "print(f\"   - SibSp y Parch: rango 0-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f6e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n visual de escalas\n",
    "df_clean = df[features_for_scaling].dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot([df_clean[col] for col in features_for_scaling], labels=features_for_scaling)\n",
    "plt.title('Comparaci√≥n de Escalas - Datos Originales', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Valor')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Los boxplots muestran que 'Fare' tiene una escala mucho mayor que las dem√°s variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400e5b0",
   "metadata": {},
   "source": [
    "## 4. M√©todo 1: StandardScaler (Estandarizaci√≥n)\n",
    "\n",
    "**F√≥rmula**: $z = \\frac{x - \\mu}{\\sigma}$\n",
    "\n",
    "Donde:\n",
    "- $x$ = valor original\n",
    "- $\\mu$ = media\n",
    "- $\\sigma$ = desviaci√≥n est√°ndar\n",
    "\n",
    "**Resultado**: Media = 0, Desviaci√≥n est√°ndar = 1\n",
    "\n",
    "**Cu√°ndo usar**:\n",
    "- Cuando los datos siguen una distribuci√≥n normal o aproximadamente normal\n",
    "- Para algoritmos que asumen distribuci√≥n normal (Regresi√≥n Log√≠stica, SVM)\n",
    "- Cuando hay outliers moderados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos (eliminar nulos para este ejemplo)\n",
    "df_clean = df[features_for_scaling].dropna().copy()\n",
    "\n",
    "# Aplicar StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = pd.DataFrame(\n",
    "    scaler_standard.fit_transform(df_clean),\n",
    "    columns=[f'{col}_standard' for col in features_for_scaling],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "print(\"Estad√≠sticas despu√©s de StandardScaler:\")\n",
    "print(\"=\"*70)\n",
    "print(df_standard.describe())\n",
    "print(\"\\n‚úì Media ‚âà 0, Desviaci√≥n est√°ndar ‚âà 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4acddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el efecto de StandardScaler\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(features_for_scaling):\n",
    "    axes[idx].hist(df_standard[f'{col}_standard'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[idx].set_title(f'{col} - StandardScaler', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Valor Estandarizado')\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "    axes[idx].axvline(0, color='red', linestyle='--', label='Media = 0')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8b262",
   "metadata": {},
   "source": [
    "## 5. M√©todo 2: MinMaxScaler (Normalizaci√≥n)\n",
    "\n",
    "**F√≥rmula**: $x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n",
    "\n",
    "**Resultado**: Valores en el rango [0, 1]\n",
    "\n",
    "**Cu√°ndo usar**:\n",
    "- Cuando necesitas datos en un rango espec√≠fico (0-1)\n",
    "- Para redes neuronales\n",
    "- Cuando NO hay outliers extremos\n",
    "- Para algoritmos que esperan datos en un rango fijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395eec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(\n",
    "    scaler_minmax.fit_transform(df_clean),\n",
    "    columns=[f'{col}_minmax' for col in features_for_scaling],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "print(\"Estad√≠sticas despu√©s de MinMaxScaler:\")\n",
    "print(\"=\"*70)\n",
    "print(df_minmax.describe())\n",
    "print(\"\\n‚úì Valores entre 0 y 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab037cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el efecto de MinMaxScaler\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(features_for_scaling):\n",
    "    axes[idx].hist(df_minmax[f'{col}_minmax'], bins=30, edgecolor='black', alpha=0.7, color='blue')\n",
    "    axes[idx].set_title(f'{col} - MinMaxScaler', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Valor Normalizado [0, 1]')\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "    axes[idx].set_xlim(-0.1, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5f30a",
   "metadata": {},
   "source": [
    "## 6. M√©todo 3: RobustScaler (Escalado Robusto)\n",
    "\n",
    "**F√≥rmula**: $x_{scaled} = \\frac{x - Q_2}{Q_3 - Q_1}$\n",
    "\n",
    "Donde:\n",
    "- $Q_2$ = mediana\n",
    "- $Q_1$ = percentil 25\n",
    "- $Q_3$ = percentil 75\n",
    "\n",
    "**Cu√°ndo usar**:\n",
    "- **Cuando hay OUTLIERS**\n",
    "- Usa la mediana en lugar de la media\n",
    "- Usa el rango intercuart√≠lico (IQR) en lugar de la desviaci√≥n est√°ndar\n",
    "- M√°s robusto a valores extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar RobustScaler\n",
    "scaler_robust = RobustScaler()\n",
    "df_robust = pd.DataFrame(\n",
    "    scaler_robust.fit_transform(df_clean),\n",
    "    columns=[f'{col}_robust' for col in features_for_scaling],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "print(\"Estad√≠sticas despu√©s de RobustScaler:\")\n",
    "print(\"=\"*70)\n",
    "print(df_robust.describe())\n",
    "print(\"\\n‚úì Centrado en la mediana, escalado por IQR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de los tres m√©todos para la variable 'Fare' (que tiene outliers)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Original\n",
    "axes[0].hist(df_clean['Fare'], bins=30, edgecolor='black', alpha=0.7, color='gray')\n",
    "axes[0].set_title('Original', fontweight='bold')\n",
    "axes[0].set_xlabel('Fare')\n",
    "\n",
    "# StandardScaler\n",
    "axes[1].hist(df_standard['Fare_standard'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].set_title('StandardScaler', fontweight='bold')\n",
    "axes[1].set_xlabel('Fare Estandarizado')\n",
    "\n",
    "# MinMaxScaler\n",
    "axes[2].hist(df_minmax['Fare_minmax'], bins=30, edgecolor='black', alpha=0.7, color='blue')\n",
    "axes[2].set_title('MinMaxScaler', fontweight='bold')\n",
    "axes[2].set_xlabel('Fare Normalizado')\n",
    "\n",
    "# RobustScaler\n",
    "axes[3].hist(df_robust['Fare_robust'], bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[3].set_title('RobustScaler', fontweight='bold')\n",
    "axes[3].set_xlabel('Fare Robusto')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observa c√≥mo RobustScaler maneja mejor los outliers en 'Fare'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b662750",
   "metadata": {},
   "source": [
    "## 7. Comparaci√≥n Lado a Lado de Todos los M√©todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33891a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa\n",
    "comparison = pd.DataFrame({\n",
    "    'M√©trica': ['Media', 'Std', 'Min', 'Max', 'Q1', 'Q2 (Mediana)', 'Q3'],\n",
    "    'Original': [\n",
    "        df_clean['Fare'].mean(),\n",
    "        df_clean['Fare'].std(),\n",
    "        df_clean['Fare'].min(),\n",
    "        df_clean['Fare'].max(),\n",
    "        df_clean['Fare'].quantile(0.25),\n",
    "        df_clean['Fare'].quantile(0.50),\n",
    "        df_clean['Fare'].quantile(0.75)\n",
    "    ],\n",
    "    'StandardScaler': [\n",
    "        df_standard['Fare_standard'].mean(),\n",
    "        df_standard['Fare_standard'].std(),\n",
    "        df_standard['Fare_standard'].min(),\n",
    "        df_standard['Fare_standard'].max(),\n",
    "        df_standard['Fare_standard'].quantile(0.25),\n",
    "        df_standard['Fare_standard'].quantile(0.50),\n",
    "        df_standard['Fare_standard'].quantile(0.75)\n",
    "    ],\n",
    "    'MinMaxScaler': [\n",
    "        df_minmax['Fare_minmax'].mean(),\n",
    "        df_minmax['Fare_minmax'].std(),\n",
    "        df_minmax['Fare_minmax'].min(),\n",
    "        df_minmax['Fare_minmax'].max(),\n",
    "        df_minmax['Fare_minmax'].quantile(0.25),\n",
    "        df_minmax['Fare_minmax'].quantile(0.50),\n",
    "        df_minmax['Fare_minmax'].quantile(0.75)\n",
    "    ],\n",
    "    'RobustScaler': [\n",
    "        df_robust['Fare_robust'].mean(),\n",
    "        df_robust['Fare_robust'].std(),\n",
    "        df_robust['Fare_robust'].min(),\n",
    "        df_robust['Fare_robust'].max(),\n",
    "        df_robust['Fare_robust'].quantile(0.25),\n",
    "        df_robust['Fare_robust'].quantile(0.50),\n",
    "        df_robust['Fare_robust'].quantile(0.75)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Comparaci√≥n de M√©todos de Escalado para 'Fare':\")\n",
    "print(\"=\"*90)\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c63d5",
   "metadata": {},
   "source": [
    "## 8. Impacto en el Rendimiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para modelado\n",
    "df_model = df[['Age', 'Fare', 'SibSp', 'Parch', 'Survived']].dropna()\n",
    "\n",
    "X = df_model[['Age', 'Fare', 'SibSp', 'Parch']]\n",
    "y = df_model['Survived']\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Funci√≥n para entrenar y evaluar\n",
    "def train_evaluate(X_train, X_test, y_train, y_test, scaler_name=\"Sin escalar\"):\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Evaluar sin escalar\n",
    "acc_no_scaling = train_evaluate(X_train, X_test, y_train, y_test, \"Sin escalar\")\n",
    "\n",
    "# Evaluar con StandardScaler\n",
    "scaler_std = StandardScaler()\n",
    "X_train_std = scaler_std.fit_transform(X_train)\n",
    "X_test_std = scaler_std.transform(X_test)\n",
    "acc_standard = train_evaluate(X_train_std, X_test_std, y_train, y_test, \"StandardScaler\")\n",
    "\n",
    "# Evaluar con MinMaxScaler\n",
    "scaler_mm = MinMaxScaler()\n",
    "X_train_mm = scaler_mm.fit_transform(X_train)\n",
    "X_test_mm = scaler_mm.transform(X_test)\n",
    "acc_minmax = train_evaluate(X_train_mm, X_test_mm, y_train, y_test, \"MinMaxScaler\")\n",
    "\n",
    "# Evaluar con RobustScaler\n",
    "scaler_rb = RobustScaler()\n",
    "X_train_rb = scaler_rb.fit_transform(X_train)\n",
    "X_test_rb = scaler_rb.transform(X_test)\n",
    "acc_robust = train_evaluate(X_train_rb, X_test_rb, y_train, y_test, \"RobustScaler\")\n",
    "\n",
    "# Mostrar resultados\n",
    "results = pd.DataFrame({\n",
    "    'M√©todo': ['Sin escalar', 'StandardScaler', 'MinMaxScaler', 'RobustScaler'],\n",
    "    'Accuracy': [acc_no_scaling, acc_standard, acc_minmax, acc_robust]\n",
    "})\n",
    "\n",
    "print(\"\\nComparaci√≥n de Rendimiento (Regresi√≥n Log√≠stica):\")\n",
    "print(\"=\"*60)\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb628ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci√≥n\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(results['M√©todo'], results['Accuracy'], color=['gray', 'green', 'blue', 'orange'], alpha=0.7, edgecolor='black')\n",
    "plt.title('Comparaci√≥n de Accuracy seg√∫n M√©todo de Escalado', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xlabel('M√©todo de Escalado', fontsize=12)\n",
    "plt.ylim(0.6, 0.75)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# A√±adir valores sobre las barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}',\n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568778d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTE II: CODIFICACI√ìN CATEG√ìRICA\n",
    "\n",
    "## ¬øPor qu√© codificar variables categ√≥ricas?\n",
    "\n",
    "Los algoritmos de Machine Learning trabajan con n√∫meros, no con texto. Necesitamos convertir variables categ√≥ricas en num√©ricas.\n",
    "\n",
    "**Tipos de variables categ√≥ricas**:\n",
    "1. **Nominales**: Sin orden (Ej: Color, Ciudad, Sexo)\n",
    "2. **Ordinales**: Con orden (Ej: Educaci√≥n, Satisfacci√≥n, Clase del Titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8e025",
   "metadata": {},
   "source": [
    "## 9. Exploraci√≥n de Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categ√≥ricas en el dataset\n",
    "categorical_features = ['Sex', 'Embarked', 'Pclass']\n",
    "\n",
    "for col in categorical_features:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Variable: {col}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(f\"\\nN√∫mero de categor√≠as √∫nicas: {df[col].nunique()}\")\n",
    "    print(f\"Valores nulos: {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuci√≥n de variables categ√≥ricas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, col in enumerate(categorical_features):\n",
    "    df[col].value_counts().plot(kind='bar', ax=axes[idx], color='skyblue', edgecolor='black')\n",
    "    axes[idx].set_title(f'Distribuci√≥n de {col}', fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c152e",
   "metadata": {},
   "source": [
    "## 10. M√©todo 1: Label Encoding\n",
    "\n",
    "Asigna un n√∫mero entero a cada categor√≠a.\n",
    "\n",
    "**Ejemplo**: male=0, female=1\n",
    "\n",
    "**Cu√°ndo usar**:\n",
    "- ‚úÖ Variables ordinales (con orden natural)\n",
    "- ‚úÖ Variables objetivo (target)\n",
    "- ‚úÖ √Årboles de decisi√≥n\n",
    "\n",
    "**Cu√°ndo NO usar**:\n",
    "- ‚ùå Variables nominales en modelos lineales (implica orden artificial)\n",
    "- ‚ùå Cuando el orden no tiene sentido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding para 'Sex'\n",
    "df_label = df.copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_label['Sex_Encoded'] = label_encoder.fit_transform(df_label['Sex'])\n",
    "\n",
    "print(\"Label Encoding de 'Sex':\")\n",
    "print(\"=\"*50)\n",
    "print(df_label[['Sex', 'Sex_Encoded']].drop_duplicates().sort_values('Sex_Encoded'))\n",
    "\n",
    "print(\"\\nMapeo:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {label} ‚Üí {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding para 'Embarked'\n",
    "df_label['Embarked_Encoded'] = label_encoder.fit_transform(df_label['Embarked'].fillna('Unknown'))\n",
    "\n",
    "print(\"Label Encoding de 'Embarked':\")\n",
    "print(\"=\"*50)\n",
    "print(df_label[['Embarked', 'Embarked_Encoded']].drop_duplicates().sort_values('Embarked_Encoded'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b76494",
   "metadata": {},
   "source": [
    "## 11. M√©todo 2: Ordinal Encoding\n",
    "\n",
    "Similar a Label Encoding, pero permite especificar el orden manualmente.\n",
    "\n",
    "**Cu√°ndo usar**:\n",
    "- Variables ordinales donde el orden es importante\n",
    "- Ejemplo: Educaci√≥n (Primaria < Secundaria < Universidad)\n",
    "- Ejemplo en Titanic: Pclass (1¬™ clase > 2¬™ clase > 3¬™ clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ce008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding para 'Pclass' (tiene orden: 1 > 2 > 3)\n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    categories=[[1, 2, 3]]  # Especificamos el orden\n",
    ")\n",
    "\n",
    "df_ordinal = df.copy()\n",
    "df_ordinal['Pclass_Ordinal'] = ordinal_encoder.fit_transform(df_ordinal[['Pclass']])\n",
    "\n",
    "print(\"Ordinal Encoding de 'Pclass':\")\n",
    "print(\"=\"*50)\n",
    "print(df_ordinal[['Pclass', 'Pclass_Ordinal']].drop_duplicates().sort_values('Pclass'))\n",
    "\n",
    "print(\"\\nüí° Pclass ya es num√©rico, pero podemos usarlo como ejemplo de variable ordinal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95334f",
   "metadata": {},
   "source": [
    "## 12. M√©todo 3: One-Hot Encoding\n",
    "\n",
    "Crea una columna binaria (0/1) para cada categor√≠a.\n",
    "\n",
    "**Ejemplo**: \n",
    "- Embarked=S ‚Üí Embarked_S=1, Embarked_C=0, Embarked_Q=0\n",
    "- Embarked=C ‚Üí Embarked_S=0, Embarked_C=1, Embarked_Q=0\n",
    "\n",
    "**Cu√°ndo usar**:\n",
    "- ‚úÖ Variables nominales (sin orden)\n",
    "- ‚úÖ Modelos lineales, SVM, Redes Neuronales\n",
    "- ‚úÖ Cuando las categor√≠as no tienen relaci√≥n ordinal\n",
    "\n",
    "**Desventajas**:\n",
    "- ‚ùå Aumenta la dimensionalidad (muchas columnas)\n",
    "- ‚ùå Problema con alta cardinalidad (muchas categor√≠as √∫nicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding con pandas get_dummies\n",
    "df_onehot = df[['Sex', 'Embarked', 'Pclass']].copy()\n",
    "df_onehot_encoded = pd.get_dummies(df_onehot, columns=['Sex', 'Embarked'], prefix=['Sex', 'Embarked'])\n",
    "\n",
    "print(\"Antes de One-Hot Encoding:\")\n",
    "print(\"=\"*50)\n",
    "print(df_onehot.head())\n",
    "\n",
    "print(\"\\n\\nDespu√©s de One-Hot Encoding:\")\n",
    "print(\"=\"*50)\n",
    "print(df_onehot_encoded.head())\n",
    "\n",
    "print(f\"\\nColumnas originales: {df_onehot.shape[1]}\")\n",
    "print(f\"Columnas despu√©s de One-Hot: {df_onehot_encoded.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding con sklearn (m√°s control)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' evita multicolinealidad\n",
    "\n",
    "# Codificar 'Embarked'\n",
    "embarked_encoded = onehot_encoder.fit_transform(df[['Embarked']].fillna('Unknown'))\n",
    "embarked_feature_names = onehot_encoder.get_feature_names_out(['Embarked'])\n",
    "\n",
    "df_onehot_sklearn = pd.DataFrame(\n",
    "    embarked_encoded,\n",
    "    columns=embarked_feature_names,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "print(\"One-Hot Encoding de 'Embarked' (con drop='first'):\")\n",
    "print(\"=\"*60)\n",
    "print(df_onehot_sklearn.head(10))\n",
    "\n",
    "print(\"\\nüí° Con drop='first', eliminamos una columna para evitar multicolinealidad.\")\n",
    "print(\"   (Si todas las otras son 0, sabemos que es la categor√≠a eliminada)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ae13d",
   "metadata": {},
   "source": [
    "## 13. Comparaci√≥n de M√©todos de Codificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeee2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame comparativo\n",
    "sample_data = pd.DataFrame({\n",
    "    'Original': ['C', 'S', 'Q', 'S', 'C'],\n",
    "})\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "sample_data['Label_Encoding'] = le.fit_transform(sample_data['Original'])\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_sample = pd.get_dummies(sample_data['Original'], prefix='OneHot')\n",
    "\n",
    "# Combinar\n",
    "comparison_df = pd.concat([sample_data, onehot_sample], axis=1)\n",
    "\n",
    "print(\"Comparaci√≥n de M√©todos de Codificaci√≥n:\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc8a9f",
   "metadata": {},
   "source": [
    "## 14. Impacto en el Rendimiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos con diferentes codificaciones\n",
    "df_model_cat = df[['Age', 'Fare', 'Sex', 'Embarked', 'Pclass', 'Survived']].copy()\n",
    "df_model_cat = df_model_cat.dropna()\n",
    "\n",
    "# 1. Con Label Encoding\n",
    "df_label_model = df_model_cat.copy()\n",
    "df_label_model['Sex'] = LabelEncoder().fit_transform(df_label_model['Sex'])\n",
    "df_label_model['Embarked'] = LabelEncoder().fit_transform(df_label_model['Embarked'])\n",
    "\n",
    "X_label = df_label_model.drop('Survived', axis=1)\n",
    "y_label = df_label_model['Survived']\n",
    "\n",
    "X_train_label, X_test_label, y_train_label, y_test_label = train_test_split(\n",
    "    X_label, y_label, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalar y entrenar\n",
    "scaler = StandardScaler()\n",
    "X_train_label_scaled = scaler.fit_transform(X_train_label)\n",
    "X_test_label_scaled = scaler.transform(X_test_label)\n",
    "\n",
    "model_label = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_label.fit(X_train_label_scaled, y_train_label)\n",
    "acc_label = accuracy_score(y_test_label, model_label.predict(X_test_label_scaled))\n",
    "\n",
    "print(f\"Accuracy con Label Encoding: {acc_label:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752bc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Con One-Hot Encoding\n",
    "df_onehot_model = df_model_cat.copy()\n",
    "df_onehot_model = pd.get_dummies(df_onehot_model, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "X_onehot = df_onehot_model.drop('Survived', axis=1)\n",
    "y_onehot = df_onehot_model['Survived']\n",
    "\n",
    "X_train_onehot, X_test_onehot, y_train_onehot, y_test_onehot = train_test_split(\n",
    "    X_onehot, y_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalar y entrenar\n",
    "scaler_oh = StandardScaler()\n",
    "X_train_onehot_scaled = scaler_oh.fit_transform(X_train_onehot)\n",
    "X_test_onehot_scaled = scaler_oh.transform(X_test_onehot)\n",
    "\n",
    "model_onehot = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_onehot.fit(X_train_onehot_scaled, y_train_onehot)\n",
    "acc_onehot = accuracy_score(y_test_onehot, model_onehot.predict(X_test_onehot_scaled))\n",
    "\n",
    "print(f\"Accuracy con One-Hot Encoding: {acc_onehot:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19957fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n final\n",
    "encoding_results = pd.DataFrame({\n",
    "    'M√©todo': ['Label Encoding', 'One-Hot Encoding'],\n",
    "    'Accuracy': [acc_label, acc_onehot],\n",
    "    'N¬∫ Features': [X_train_label.shape[1], X_train_onehot.shape[1]]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACI√ìN DE M√âTODOS DE CODIFICACI√ìN\")\n",
    "print(\"=\"*70)\n",
    "print(encoding_results.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° One-Hot Encoding generalmente funciona mejor para variables nominales,\")\n",
    "print(\"   aunque aumenta el n√∫mero de caracter√≠sticas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe20570",
   "metadata": {},
   "source": [
    "## 15. Gu√≠a de Decisi√≥n: ¬øQu√© M√©todo Usar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb314f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla de decisi√≥n\n",
    "decision_guide = pd.DataFrame({\n",
    "    'Escenario': [\n",
    "        'Variable nominal + Modelo lineal',\n",
    "        'Variable nominal + √Årbol de decisi√≥n',\n",
    "        'Variable ordinal',\n",
    "        'Muchas categor√≠as (>10)',\n",
    "        'Target variable (y)',\n",
    "        'Datos con outliers',\n",
    "        'Redes Neuronales',\n",
    "        'Sin outliers + Modelo lineal'\n",
    "    ],\n",
    "    'Normalizaci√≥n': [\n",
    "        'StandardScaler',\n",
    "        'No necesario',\n",
    "        'StandardScaler',\n",
    "        'RobustScaler',\n",
    "        'No aplicable',\n",
    "        'RobustScaler',\n",
    "        'MinMaxScaler',\n",
    "        'StandardScaler o MinMax'\n",
    "    ],\n",
    "    'Codificaci√≥n': [\n",
    "        'One-Hot Encoding',\n",
    "        'Label Encoding',\n",
    "        'Ordinal Encoding',\n",
    "        'Target/Frequency Encoding',\n",
    "        'Label Encoding',\n",
    "        'No aplicable',\n",
    "        'One-Hot Encoding',\n",
    "        'One-Hot Encoding'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"GU√çA DE DECISI√ìN: NORMALIZACI√ìN Y CODIFICACI√ìN\")\n",
    "print(\"=\"*90)\n",
    "print(decision_guide.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80181c9f",
   "metadata": {},
   "source": [
    "## 16. Ejemplo Completo: Pipeline de Transformaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa18342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Definir caracter√≠sticas\n",
    "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "categorical_features = ['Sex', 'Embarked', 'Pclass']\n",
    "\n",
    "# Pipeline para variables num√©ricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())  # Usamos RobustScaler por los outliers en Fare\n",
    "])\n",
    "\n",
    "# Pipeline para variables categ√≥ricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinar con ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Preparar datos\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "acc_pipeline = full_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE COMPLETO DE TRANSFORMACI√ìN\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAccuracy: {acc_pipeline:.4f}\")\n",
    "print(f\"\\n‚úì Variables num√©ricas: Imputadas con mediana + RobustScaler\")\n",
    "print(f\"‚úì Variables categ√≥ricas: Imputadas + One-Hot Encoding\")\n",
    "print(f\"‚úì Modelo: Regresi√≥n Log√≠stica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41acae",
   "metadata": {},
   "source": [
    "## 17. Resumen y Mejores Pr√°cticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa98de0",
   "metadata": {},
   "source": [
    "### üìä Normalizaci√≥n/Escalado:\n",
    "\n",
    "| M√©todo | F√≥rmula | Cu√°ndo usar | Resultado |\n",
    "|--------|---------|-------------|------------|\n",
    "| **StandardScaler** | $(x - \\mu) / \\sigma$ | Datos normales, sin outliers extremos | Media=0, Std=1 |\n",
    "| **MinMaxScaler** | $(x - min) / (max - min)$ | Necesitas rango [0,1], sin outliers | Rango [0, 1] |\n",
    "| **RobustScaler** | $(x - Q_2) / (Q_3 - Q_1)$ | **CON OUTLIERS** | Robusto a outliers |\n",
    "\n",
    "### üè∑Ô∏è Codificaci√≥n Categ√≥rica:\n",
    "\n",
    "| M√©todo | Descripci√≥n | Cu√°ndo usar | Dimensionalidad |\n",
    "|--------|-------------|-------------|------------------|\n",
    "| **Label Encoding** | Asigna n√∫meros (0,1,2...) | Variables ordinales, target, √°rboles | No aumenta |\n",
    "| **Ordinal Encoding** | Asigna n√∫meros con orden | Variables ordinales con orden espec√≠fico | No aumenta |\n",
    "| **One-Hot Encoding** | Crea columna binaria por categor√≠a | Variables nominales, modelos lineales | Aumenta (n-1 o n) |\n",
    "\n",
    "### ‚úÖ Reglas de Oro:\n",
    "\n",
    "1. **SIEMPRE** usa `fit_transform()` en datos de entrenamiento\n",
    "2. **SIEMPRE** usa solo `transform()` en datos de prueba\n",
    "3. **Usa pipelines** para evitar errores y fuga de datos\n",
    "4. **RobustScaler** es tu amigo cuando hay outliers\n",
    "5. **One-Hot** para nominales, **Ordinal** para ordinales\n",
    "6. **Escala DESPU√âS de dividir** train/test\n",
    "7. **Guarda el scaler/encoder** para usar en producci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69436c96",
   "metadata": {},
   "source": [
    "## 18. Ejercicios Pr√°cticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67edca",
   "metadata": {},
   "source": [
    "### Ejercicio 1:\n",
    "Compara el rendimiento de un modelo con diferentes combinaciones de escaladores y encoders. ¬øCu√°l da mejor resultado?\n",
    "\n",
    "### Ejercicio 2:\n",
    "Crea un transformador personalizado que:\n",
    "- Detecte autom√°ticamente outliers\n",
    "- Aplique el escalador apropiado seg√∫n la presencia de outliers\n",
    "\n",
    "### Ejercicio 3:\n",
    "Implementa Target Encoding para variables categ√≥ricas con alta cardinalidad y compara con One-Hot Encoding.\n",
    "\n",
    "### Ejercicio 4:\n",
    "Analiza el impacto de `drop='first'` vs `drop=None` en One-Hot Encoding para prevenir multicolinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a12eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para tus ejercicios"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

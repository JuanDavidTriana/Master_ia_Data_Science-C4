{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c37d1a0",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Para mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f906e",
   "metadata": {},
   "source": [
    "## 2. Cargar y Explorar el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset del Titanic\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192dea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del dataset\n",
    "print(\"Información del dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"Número de filas: {df.shape[0]}\")\n",
    "print(f\"Número de columnas: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d61dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4e77f",
   "metadata": {},
   "source": [
    "## 3. Manejo de Valores Nulos\n",
    "\n",
    "Los valores nulos (NaN, None, NA) son uno de los problemas más comunes en datasets reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e4c74",
   "metadata": {},
   "source": [
    "### 3.1 Identificar Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar valores nulos por columna\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e962169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje de valores nulos por columna\n",
    "print(\"Porcentaje de valores nulos por columna:\")\n",
    "porcentaje_nulos = (df.isnull().sum() / len(df)) * 100\n",
    "porcentaje_nulos[porcentaje_nulos > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de valores nulos\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
    "plt.title('Mapa de Valores Nulos en el Dataset')\n",
    "plt.xlabel('Columnas')\n",
    "plt.ylabel('Filas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc47b91",
   "metadata": {},
   "source": [
    "### 3.2 Estrategias para Manejar Valores Nulos\n",
    "\n",
    "Existen varias estrategias:\n",
    "1. **Eliminar filas/columnas** con valores nulos\n",
    "2. **Imputar con medidas estadísticas** (media, mediana, moda)\n",
    "3. **Imputar con valores calculados** (forward fill, backward fill)\n",
    "4. **Imputar con valores constantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del dataframe para trabajar\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(f\"Filas originales: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53b1d2",
   "metadata": {},
   "source": [
    "#### Estrategia 1: Eliminar filas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ff90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver cuántas filas perderíamos si eliminamos todas las que tienen algún nulo\n",
    "filas_completas = df_clean.dropna()\n",
    "print(f\"Filas después de eliminar todas con valores nulos: {len(filas_completas)}\")\n",
    "print(f\"Filas perdidas: {len(df_clean) - len(filas_completas)}\")\n",
    "print(f\"Porcentaje de datos perdidos: {((len(df_clean) - len(filas_completas)) / len(df_clean) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e5aa4",
   "metadata": {},
   "source": [
    "#### Estrategia 2: Imputación con medidas estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489baadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar la columna 'Age' con la mediana (más robusta a outliers que la media)\n",
    "if 'Age' in df_clean.columns:\n",
    "    mediana_edad = df_clean['Age'].median()\n",
    "    print(f\"Mediana de edad: {mediana_edad:.2f}\")\n",
    "    df_clean['Age'].fillna(mediana_edad, inplace=True)\n",
    "    print(f\"Valores nulos en 'Age' después de imputación: {df_clean['Age'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83806064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar 'Embarked' con la moda (valor más frecuente)\n",
    "if 'Embarked' in df_clean.columns:\n",
    "    moda_embarked = df_clean['Embarked'].mode()[0]\n",
    "    print(f\"Moda de Embarked: {moda_embarked}\")\n",
    "    df_clean['Embarked'].fillna(moda_embarked, inplace=True)\n",
    "    print(f\"Valores nulos en 'Embarked' después de imputación: {df_clean['Embarked'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9dd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para columnas con muchos valores nulos (como 'Cabin'), puede ser mejor eliminarlas o crear una categoría\n",
    "if 'Cabin' in df_clean.columns:\n",
    "    # Opción 1: Crear una categoría 'Desconocido'\n",
    "    df_clean['Cabin'].fillna('Desconocido', inplace=True)\n",
    "    print(f\"Valores nulos en 'Cabin' después de imputación: {df_clean['Cabin'].isnull().sum()}\")\n",
    "    \n",
    "    # O podríamos crear una variable binaria indicando si tiene cabina o no\n",
    "    df_clean['Tiene_Cabina'] = df_clean['Cabin'].apply(lambda x: 0 if x == 'Desconocido' else 1)\n",
    "    print(\"\\nDistribución de 'Tiene_Cabina':\")\n",
    "    print(df_clean['Tiene_Cabina'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54199b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos restantes\n",
    "print(\"Valores nulos restantes:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af2ca94",
   "metadata": {},
   "source": [
    "## 4. Detección y Manejo de Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c541807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar duplicados completos (todas las columnas iguales)\n",
    "print(f\"Número de filas duplicadas completas: {df_clean.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bf1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver las filas duplicadas si existen\n",
    "if df_clean.duplicated().sum() > 0:\n",
    "    print(\"Filas duplicadas:\")\n",
    "    print(df_clean[df_clean.duplicated(keep=False)].sort_values(by=df_clean.columns[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar duplicados en columnas específicas (por ejemplo, en 'PassengerId')\n",
    "if 'PassengerId' in df_clean.columns:\n",
    "    duplicados_id = df_clean.duplicated(subset=['PassengerId']).sum()\n",
    "    print(f\"Duplicados en PassengerId: {duplicados_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b020976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados\n",
    "filas_antes = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "filas_despues = len(df_clean)\n",
    "print(f\"Filas eliminadas: {filas_antes - filas_despues}\")\n",
    "print(f\"Filas restantes: {filas_despues}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ce7cb",
   "metadata": {},
   "source": [
    "## 5. Detección y Manejo de Outliers\n",
    "\n",
    "Los outliers son valores atípicos que se desvían significativamente del resto de los datos.\n",
    "\n",
    "### Métodos de detección:\n",
    "1. **Método IQR (Rango Intercuartílico)**\n",
    "2. **Z-Score**\n",
    "3. **Visualización (boxplots)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3afd000",
   "metadata": {},
   "source": [
    "### 5.1 Visualización de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas numéricas\n",
    "columnas_numericas = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Columnas numéricas: {columnas_numericas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feff4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear boxplots para identificar outliers visualmente\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(columnas_numericas[:6]):\n",
    "    axes[idx].boxplot(df_clean[col].dropna())\n",
    "    axes[idx].set_title(f'Boxplot de {col}')\n",
    "    axes[idx].set_ylabel('Valor')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9344a9be",
   "metadata": {},
   "source": [
    "### 5.2 Método IQR (Rango Intercuartílico)\n",
    "\n",
    "Un outlier es un valor que está fuera del rango:\n",
    "- **Límite inferior**: Q1 - 1.5 × IQR\n",
    "- **Límite superior**: Q3 + 1.5 × IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_iqr(df, columna):\n",
    "    \"\"\"\n",
    "    Detecta outliers usando el método IQR.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame\n",
    "    - columna: nombre de la columna a analizar\n",
    "    \n",
    "    Retorna:\n",
    "    - Serie booleana indicando outliers\n",
    "    \"\"\"\n",
    "    Q1 = df[columna].quantile(0.25)\n",
    "    Q3 = df[columna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    print(f\"\\n--- Análisis de '{columna}' ---\")\n",
    "    print(f\"Q1 (25%): {Q1:.2f}\")\n",
    "    print(f\"Q3 (75%): {Q3:.2f}\")\n",
    "    print(f\"IQR: {IQR:.2f}\")\n",
    "    print(f\"Límite inferior: {limite_inferior:.2f}\")\n",
    "    print(f\"Límite superior: {limite_superior:.2f}\")\n",
    "    \n",
    "    outliers = (df[columna] < limite_inferior) | (df[columna] > limite_superior)\n",
    "    print(f\"Número de outliers: {outliers.sum()}\")\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar outliers en la columna 'Age'\n",
    "if 'Age' in df_clean.columns:\n",
    "    outliers_edad = detectar_outliers_iqr(df_clean, 'Age')\n",
    "    print(f\"\\nEdades consideradas outliers:\")\n",
    "    print(df_clean[outliers_edad]['Age'].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar outliers en la columna 'Fare'\n",
    "if 'Fare' in df_clean.columns:\n",
    "    outliers_fare = detectar_outliers_iqr(df_clean, 'Fare')\n",
    "    print(f\"\\nTarifas consideradas outliers (primeras 10):\")\n",
    "    print(df_clean[outliers_fare]['Fare'].sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dca438",
   "metadata": {},
   "source": [
    "### 5.3 Método Z-Score\n",
    "\n",
    "Un valor se considera outlier si su Z-Score es mayor a 3 o menor a -3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_zscore(df, columna, umbral=3):\n",
    "    \"\"\"\n",
    "    Detecta outliers usando el método Z-Score.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame\n",
    "    - columna: nombre de la columna a analizar\n",
    "    - umbral: valor umbral del Z-Score (por defecto 3)\n",
    "    \n",
    "    Retorna:\n",
    "    - Serie booleana indicando outliers\n",
    "    \"\"\"\n",
    "    media = df[columna].mean()\n",
    "    std = df[columna].std()\n",
    "    \n",
    "    z_scores = np.abs((df[columna] - media) / std)\n",
    "    \n",
    "    print(f\"\\n--- Análisis Z-Score de '{columna}' ---\")\n",
    "    print(f\"Media: {media:.2f}\")\n",
    "    print(f\"Desviación estándar: {std:.2f}\")\n",
    "    print(f\"Umbral Z-Score: {umbral}\")\n",
    "    \n",
    "    outliers = z_scores > umbral\n",
    "    print(f\"Número de outliers: {outliers.sum()}\")\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8567f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar outliers en 'Fare' usando Z-Score\n",
    "if 'Fare' in df_clean.columns:\n",
    "    outliers_fare_zscore = detectar_outliers_zscore(df_clean, 'Fare')\n",
    "    print(f\"\\nTarifas outliers por Z-Score:\")\n",
    "    print(df_clean[outliers_fare_zscore][['Name', 'Fare']].sort_values('Fare', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff6ef9",
   "metadata": {},
   "source": [
    "### 5.4 Estrategias para Manejar Outliers\n",
    "\n",
    "1. **Eliminar**: Solo si están claramente equivocados\n",
    "2. **Transformar**: Aplicar logaritmo o raíz cuadrada\n",
    "3. **Limitar**: Cap/floor a un valor máximo/mínimo\n",
    "4. **Mantener**: Si son valores válidos y representan casos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afd1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 1: Eliminar outliers extremos\n",
    "df_sin_outliers = df_clean.copy()\n",
    "\n",
    "if 'Fare' in df_sin_outliers.columns:\n",
    "    # Eliminar solo outliers muy extremos usando IQR con factor más alto\n",
    "    Q1 = df_sin_outliers['Fare'].quantile(0.25)\n",
    "    Q3 = df_sin_outliers['Fare'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_superior = Q3 + 3 * IQR  # Factor 3 en lugar de 1.5 para ser menos agresivos\n",
    "    \n",
    "    outliers_extremos = df_sin_outliers['Fare'] > limite_superior\n",
    "    print(f\"Outliers extremos en Fare (>{limite_superior:.2f}): {outliers_extremos.sum()}\")\n",
    "    \n",
    "    df_sin_outliers = df_sin_outliers[~outliers_extremos]\n",
    "    print(f\"Filas después de eliminar outliers extremos: {len(df_sin_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 2: Limitar valores (capping)\n",
    "df_capped = df_clean.copy()\n",
    "\n",
    "if 'Fare' in df_capped.columns:\n",
    "    # Limitar al percentil 95\n",
    "    limite_percentil_95 = df_capped['Fare'].quantile(0.95)\n",
    "    print(f\"Percentil 95 de Fare: {limite_percentil_95:.2f}\")\n",
    "    \n",
    "    df_capped['Fare_Capped'] = df_capped['Fare'].clip(upper=limite_percentil_95)\n",
    "    \n",
    "    print(f\"\\nComparación antes y después del capping:\")\n",
    "    print(f\"Máximo original: {df_capped['Fare'].max():.2f}\")\n",
    "    print(f\"Máximo después de capping: {df_capped['Fare_Capped'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81fd4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el efecto del capping\n",
    "if 'Fare' in df_capped.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].hist(df_capped['Fare'], bins=50, edgecolor='black')\n",
    "    axes[0].set_title('Distribución de Fare (Original)')\n",
    "    axes[0].set_xlabel('Tarifa')\n",
    "    axes[0].set_ylabel('Frecuencia')\n",
    "    \n",
    "    axes[1].hist(df_capped['Fare_Capped'], bins=50, edgecolor='black', color='orange')\n",
    "    axes[1].set_title('Distribución de Fare (Con Capping)')\n",
    "    axes[1].set_xlabel('Tarifa')\n",
    "    axes[1].set_ylabel('Frecuencia')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5708c",
   "metadata": {},
   "source": [
    "## 6. Resumen y Comparación del Dataset\n",
    "\n",
    "Comparemos el dataset original con el dataset limpio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc423bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen del proceso de limpieza\n",
    "print(\"=\"*60)\n",
    "print(\"RESUMEN DEL PROCESO DE LIMPIEZA DE DATOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. DATASET ORIGINAL:\")\n",
    "print(f\"   - Filas: {df.shape[0]}\")\n",
    "print(f\"   - Columnas: {df.shape[1]}\")\n",
    "print(f\"   - Valores nulos totales: {df.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n2. DATASET LIMPIO:\")\n",
    "print(f\"   - Filas: {df_clean.shape[0]}\")\n",
    "print(f\"   - Columnas: {df_clean.shape[1]}\")\n",
    "print(f\"   - Valores nulos totales: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n3. CAMBIOS REALIZADOS:\")\n",
    "print(f\"   - Filas eliminadas: {df.shape[0] - df_clean.shape[0]}\")\n",
    "print(f\"   - Porcentaje de datos retenidos: {(df_clean.shape[0] / df.shape[0] * 100):.2f}%\")\n",
    "print(f\"   - Valores nulos eliminados/imputados: {df.isnull().sum().sum() - df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f119020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataset limpio\n",
    "df_clean.to_csv('Titanic-Dataset-Limpio.csv', index=False)\n",
    "print(\"\\nDataset limpio guardado como 'Titanic-Dataset-Limpio.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bece4a8",
   "metadata": {},
   "source": [
    "## 7. Conclusiones y Mejores Prácticas\n",
    "\n",
    "### Lecciones aprendidas:\n",
    "\n",
    "1. **Valores Nulos:**\n",
    "   - Siempre analizar el porcentaje de valores nulos antes de decidir qué hacer\n",
    "   - Usar la mediana para variables numéricas (más robusta a outliers)\n",
    "   - Usar la moda para variables categóricas\n",
    "   - Considerar crear variables indicadoras para valores faltantes\n",
    "\n",
    "2. **Duplicados:**\n",
    "   - Verificar duplicados tanto completos como por columnas clave\n",
    "   - Entender por qué existen duplicados antes de eliminarlos\n",
    "\n",
    "3. **Outliers:**\n",
    "   - No siempre los outliers deben eliminarse - pueden ser valores válidos\n",
    "   - Usar visualizaciones para entender la naturaleza de los outliers\n",
    "   - Considerar transformaciones (log, sqrt) antes de eliminar\n",
    "   - El método IQR es más robusto que Z-Score para distribuciones no normales\n",
    "\n",
    "4. **General:**\n",
    "   - Documentar todas las decisiones de limpieza\n",
    "   - Mantener una copia del dataset original\n",
    "   - Validar que la limpieza no introdujo sesgos\n",
    "   - Considerar el contexto del negocio/dominio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f61b466",
   "metadata": {},
   "source": [
    "## 8. Ejercicios Prácticos\n",
    "\n",
    "### Ejercicio 1:\n",
    "Crea una función que automatice el proceso de limpieza para cualquier dataset, incluyendo:\n",
    "- Detección de valores nulos\n",
    "- Imputación automática según el tipo de dato\n",
    "- Detección de outliers\n",
    "\n",
    "### Ejercicio 2:\n",
    "Analiza cómo afecta la eliminación de outliers a las estadísticas descriptivas del dataset.\n",
    "\n",
    "### Ejercicio 3:\n",
    "Compara diferentes métodos de imputación (media vs mediana vs moda) y evalúa cuál es más apropiado para cada columna."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
